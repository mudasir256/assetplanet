{"ast":null,"code":"import React from 'react';\nimport PropTypes from 'prop-types';\nfunction _inheritsLoose(subClass, superClass) {\n  subClass.prototype = Object.create(superClass.prototype);\n  subClass.prototype.constructor = subClass;\n  subClass.__proto__ = superClass;\n}\nfunction _assertThisInitialized(self) {\n  if (self === void 0) {\n    throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");\n  }\n  return self;\n}\n\n// A type of promise-like that resolves synchronously and supports only one observer\n\nvar _iteratorSymbol = /*#__PURE__*/typeof Symbol !== \"undefined\" ? Symbol.iterator || (Symbol.iterator = Symbol(\"Symbol.iterator\")) : \"@@iterator\";\nvar _asyncIteratorSymbol = /*#__PURE__*/typeof Symbol !== \"undefined\" ? Symbol.asyncIterator || (Symbol.asyncIterator = Symbol(\"Symbol.asyncIterator\")) : \"@@asyncIterator\";\n\n// Asynchronously call a function and send errors to recovery continuation\nfunction _catch(body, recover) {\n  try {\n    var result = body();\n  } catch (e) {\n    return recover(e);\n  }\n  if (result && result.then) {\n    return result.then(void 0, recover);\n  }\n  return result;\n}\nvar RecordState = Object.freeze({\n  START: 'start',\n  PAUSE: 'pause',\n  STOP: 'stop',\n  NONE: 'none'\n});\nvar AudioReactRecorder = /*#__PURE__*/function (_React$Component) {\n  _inheritsLoose(AudioReactRecorder, _React$Component);\n  function AudioReactRecorder(props) {\n    var _this;\n    _this = _React$Component.call(this, props) || this;\n    _this.init = function () {\n      try {\n        _this.leftchannel = [];\n        _this.rightchannel = [];\n        _this.recorder = null;\n        _this.recording = false;\n        _this.recordingLength = 0;\n        _this.volume = null;\n        _this.audioInput = null;\n        _this.sampleRate = null;\n        _this.AudioContext = window.AudioContext || window.webkitAudioContext;\n        _this.context = null;\n        _this.analyser = null;\n        _this.canvas = _this.canvasRef.current;\n        _this.canvasCtx = _this.canvas.getContext('2d');\n        _this.stream = null;\n        _this.tested = false;\n        navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;\n        return Promise.resolve();\n      } catch (e) {\n        return Promise.reject(e);\n      }\n    };\n    _this.getStream = function (constraints) {\n      if (!constraints) {\n        constraints = {\n          audio: true,\n          video: false\n        };\n      }\n      return navigator.mediaDevices.getUserMedia(constraints);\n    };\n    _this.setUpRecording = function () {\n      _this.context = new _this.AudioContext();\n      _this.sampleRate = _this.context.sampleRate;\n      _this.volume = _this.context.createGain();\n      _this.audioInput = _this.context.createMediaStreamSource(_this.stream);\n      _this.analyser = _this.context.createAnalyser();\n      _this.audioInput.connect(_this.analyser);\n      var bufferSize = 2048;\n      _this.recorder = _this.context.createScriptProcessor(bufferSize, 2, 2);\n      _this.analyser.connect(_this.recorder);\n      _this.recorder.connect(_this.context.destination);\n      var self = _assertThisInitialized(_this);\n      _this.recorder.onaudioprocess = function (e) {\n        if (!self.recording) return;\n        var left = e.inputBuffer.getChannelData(0);\n        var right = e.inputBuffer.getChannelData(1);\n        if (!self.tested) {\n          self.tested = true;\n          if (!left.reduce(function (a, b) {\n            return a + b;\n          })) {\n            console.log('Error: There seems to be an issue with your Mic');\n            self.stop();\n            self.stream.getTracks().forEach(function (track) {\n              track.stop();\n            });\n          }\n        }\n        self.leftchannel.push(new Float32Array(left));\n        self.rightchannel.push(new Float32Array(right));\n        self.recordingLength += bufferSize;\n      };\n      _this.visualize();\n    };\n    _this.mergeBuffers = function (channelBuffer, recordingLength) {\n      var result = new Float32Array(recordingLength);\n      var offset = 0;\n      var lng = channelBuffer.length;\n      for (var i = 0; i < lng; i++) {\n        var buffer = channelBuffer[i];\n        result.set(buffer, offset);\n        offset += buffer.length;\n      }\n      return result;\n    };\n    _this.interleave = function (leftChannel, rightChannel) {\n      var length = leftChannel.length + rightChannel.length;\n      var result = new Float32Array(length);\n      var inputIndex = 0;\n      for (var index = 0; index < length;) {\n        result[index++] = leftChannel[inputIndex];\n        result[index++] = rightChannel[inputIndex];\n        inputIndex++;\n      }\n      return result;\n    };\n    _this.writeUTFBytes = function (view, offset, string) {\n      var lng = string.length;\n      for (var i = 0; i < lng; i++) {\n        view.setUint8(offset + i, string.charCodeAt(i));\n      }\n    };\n    _this.visualize = function () {\n      var _this$props = _this.props,\n        backgroundColor = _this$props.backgroundColor,\n        foregroundColor = _this$props.foregroundColor;\n      _this.WIDTH = _this.canvas.width;\n      _this.HEIGHT = _this.canvas.height;\n      _this.CENTERX = _this.canvas.width / 2;\n      _this.CENTERY = _this.canvas.height / 2;\n      if (!_this.analyser) return;\n      _this.analyser.fftSize = 2048;\n      var bufferLength = _this.analyser.fftSize;\n      var dataArray = new Uint8Array(bufferLength);\n      _this.canvasCtx.clearRect(0, 0, _this.WIDTH, _this.HEIGHT);\n      var self = _assertThisInitialized(_this);\n      var draw = function draw() {\n        self.drawVisual = requestAnimationFrame(draw);\n        self.analyser.getByteTimeDomainData(dataArray);\n        self.canvasCtx.fillStyle = backgroundColor;\n        self.canvasCtx.fillRect(0, 0, self.WIDTH, self.HEIGHT);\n        self.canvasCtx.lineWidth = 2;\n        self.canvasCtx.strokeStyle = foregroundColor;\n        self.canvasCtx.beginPath();\n        var sliceWidth = self.WIDTH * 1.0 / bufferLength;\n        var x = 0;\n        for (var i = 0; i < bufferLength; i++) {\n          var v = dataArray[i] / 128.0;\n          var y = v * self.HEIGHT / 2;\n          if (i === 0) {\n            self.canvasCtx.moveTo(x, y);\n          } else {\n            self.canvasCtx.lineTo(x, y);\n          }\n          x += sliceWidth;\n        }\n        self.canvasCtx.lineTo(self.canvas.width, self.canvas.height / 2);\n        self.canvasCtx.stroke();\n      };\n      draw();\n    };\n    _this.setupMic = function () {\n      try {\n        var _temp3 = function _temp3() {\n          _this.setUpRecording();\n        };\n        var _temp4 = _catch(function () {\n          return Promise.resolve(_this.getStream()).then(function (_this$getStream) {\n            window.stream = _this.stream = _this$getStream;\n          });\n        }, function (err) {\n          console.log('Error: Issue getting mic', err);\n        });\n        return Promise.resolve(_temp4 && _temp4.then ? _temp4.then(_temp3) : _temp3(_temp4));\n      } catch (e) {\n        return Promise.reject(e);\n      }\n    };\n    _this.start = function () {\n      try {\n        return Promise.resolve(_this.setupMic()).then(function () {\n          _this.recording = true;\n          _this.leftchannel.length = _this.rightchannel.length = 0;\n          _this.recordingLength = 0;\n        });\n      } catch (e) {\n        return Promise.reject(e);\n      }\n    };\n    _this.stop = function () {\n      var _this$props2 = _this.props,\n        onStop = _this$props2.onStop,\n        type = _this$props2.type;\n      _this.recording = false;\n      _this.closeMic();\n      _this.leftBuffer = _this.mergeBuffers(_this.leftchannel, _this.recordingLength);\n      _this.rightBuffer = _this.mergeBuffers(_this.rightchannel, _this.recordingLength);\n      var interleaved = _this.interleave(_this.leftBuffer, _this.rightBuffer);\n      var buffer = new ArrayBuffer(44 + interleaved.length * 2);\n      var view = new DataView(buffer);\n      _this.writeUTFBytes(view, 0, 'RIFF');\n      view.setUint32(4, 44 + interleaved.length * 2, true);\n      _this.writeUTFBytes(view, 8, 'WAVE');\n      _this.writeUTFBytes(view, 12, 'fmt ');\n      view.setUint32(16, 16, true);\n      view.setUint16(20, 1, true);\n      view.setUint16(22, 2, true);\n      view.setUint32(24, _this.sampleRate, true);\n      view.setUint32(28, _this.sampleRate * 4, true);\n      view.setUint16(32, 4, true);\n      view.setUint16(34, 16, true);\n      _this.writeUTFBytes(view, 36, 'data');\n      view.setUint32(40, interleaved.length * 2, true);\n      var lng = interleaved.length;\n      var index = 44;\n      var volume = 1;\n      for (var i = 0; i < lng; i++) {\n        view.setInt16(index, interleaved[i] * (0x7fff * volume), true);\n        index += 2;\n      }\n      var blob = new Blob([view], {\n        type: type\n      });\n      var audioUrl = URL.createObjectURL(blob);\n      onStop && onStop({\n        blob: blob,\n        url: audioUrl,\n        type: type\n      });\n    };\n    _this.pause = function () {\n      _this.recording = false;\n      _this.closeMic();\n    };\n    _this.resume = function () {\n      _this.setupMic();\n      _this.recording = true;\n    };\n    _this.closeMic = function () {\n      _this.stream.getAudioTracks().forEach(function (track) {\n        track.stop();\n      });\n      _this.audioInput.disconnect(0);\n      _this.analyser.disconnect(0);\n      _this.recorder.disconnect(0);\n    };\n    _this.canvasRef = React.createRef();\n    return _this;\n  }\n  var _proto = AudioReactRecorder.prototype;\n  _proto.componentDidMount = function componentDidMount() {\n    this.init();\n  };\n  _proto.componentDidUpdate = function componentDidUpdate(prevProps, prevState) {\n    var state = this.props.state;\n    this.checkState(prevProps.state, state);\n  };\n  _proto.checkState = function checkState(previousState) {\n    switch (previousState) {\n      case RecordState.START:\n        this.doIfState(RecordState.PAUSE, this.pause);\n        this.doIfState(RecordState.STOP, this.stop);\n        break;\n      case RecordState.PAUSE:\n        this.doIfState(RecordState.START, this.resume);\n        this.doIfState(RecordState.STOP, this.stop);\n        break;\n      case RecordState.STOP:\n        this.doIfState(RecordState.START, this.start);\n        break;\n      default:\n        this.doIfState(RecordState.START, this.start);\n        break;\n    }\n  };\n  _proto.doIfState = function doIfState(state, cb) {\n    if (this.props.state == state) {\n      cb && cb();\n    }\n  };\n  _proto.componentWillUnmount = function componentWillUnmount() {};\n  _proto.render = function render() {\n    var _this$props3 = this.props,\n      canvasWidth = _this$props3.canvasWidth,\n      canvasHeight = _this$props3.canvasHeight;\n    return /*#__PURE__*/React.createElement(\"div\", {\n      className: \"audio-react-recorder\"\n    }, /*#__PURE__*/React.createElement(\"canvas\", {\n      ref: this.canvasRef,\n      width: canvasWidth,\n      height: canvasHeight,\n      className: \"audio-react-recorder__canvas\"\n    }));\n  };\n  return AudioReactRecorder;\n}(React.Component);\nAudioReactRecorder.propTypes = {\n  state: PropTypes.string,\n  type: PropTypes.string.isRequired,\n  backgroundColor: PropTypes.string,\n  foregroundColor: PropTypes.string,\n  canvasWidth: PropTypes.oneOfType([PropTypes.string, PropTypes.number]),\n  canvasHeight: PropTypes.oneOfType([PropTypes.string, PropTypes.number]),\n  onStop: PropTypes.func\n};\nAudioReactRecorder.defaultProps = {\n  state: RecordState.NONE,\n  type: 'audio/wav',\n  backgroundColor: 'rgb(200, 200, 200)',\n  foregroundColor: 'rgb(0, 0, 0)',\n  canvasWidth: 500,\n  canvasHeight: 300\n};\nexport default AudioReactRecorder;\nexport { RecordState };","map":null,"metadata":{},"sourceType":"module"}